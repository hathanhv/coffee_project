"""
Main Script - Highlands Coffee Customer Segmentation

Pipeline ho√†n ch·ªânh t·ª´ preprocessing ƒë·∫øn clustering v√† visualization
"""

import os
import sys
import logging
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent))

from src.models.trainer import ModelTrainer, TrainingConfig
from src.models.evaluator import ClusteringEvaluator
from src.models.tuning import HyperparameterTuner, TuningConfig


def setup_logger():
    """Thi·∫øt l·∫≠p logger cho main script"""
    logger = logging.getLogger("Main")
    logger.setLevel(logging.INFO)
    logger.propagate = False
    
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter('%(message)s'))
        logger.addHandler(handler)
    
    return logger


def train_single_model(logger):
    """
    Mode 1: Train m·ªôt model c·ª• th·ªÉ v·ªõi c·∫•u h√¨nh c·ªë ƒë·ªãnh
    """
    logger.info("\n" + "="*80)
    logger.info("MODE 1: TRAIN SINGLE MODEL")
    logger.info("="*80)
    
    # C·∫•u h√¨nh model
    config = TrainingConfig(
        data_path="data/processed/encoded_data.csv",
        model_type="kmeans",  # C√≥ th·ªÉ ƒë·ªïi: 'kmeans', 'gmm', 'dbscan', 'hdbscan'
        n_clusters=5,
        model_params={
            "n_init": 20,
            "max_iter": 500
        },
        model_path="results/kmeans_model.pkl"
    )
    
    # Train
    evaluator = ClusteringEvaluator()
    trainer = ModelTrainer(config=config, evaluator=evaluator)
    
    trainer.load_data()
    trainer.train_model()
    metrics = trainer.evaluate()
    
    # L∆∞u k·∫øt qu·∫£
    trainer.save_model()
    trainer.save_labels("results/kmeans_labels.csv")
    
    logger.info("\n‚úÖ Single model training completed!")
    logger.info(f"   Model saved: {config.model_path}")
    logger.info(f"   Labels saved: results/kmeans_labels.csv")
    
    return trainer, metrics


def hyperparameter_tuning(logger):
    """
    Mode 2: Grid search t·∫•t c·∫£ models ƒë·ªÉ t√¨m best hyperparameters
    """
    logger.info("\n" + "="*80)
    logger.info("MODE 2: HYPERPARAMETER TUNING")
    logger.info("="*80)
    
    tuning_config = TuningConfig(
        data_path="data/processed/encoded_data.csv",
        results_path="results/tuning_results.csv",
        metric_selection="silhouette"  # 'silhouette', 'calinski_harabasz', 'davies_bouldin'
    )
    
    evaluator = ClusteringEvaluator()
    tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)
    
    # Run grid search cho t·∫•t c·∫£ models
    tuner.run_all_models()
    
    # L∆∞u k·∫øt qu·∫£
    tuner.save_results()
    tuner.save_best_model_and_df(
        model_path="results/best_model.pkl",
        df_path="results/clustered_data.csv"
    )
    
    logger.info("\n‚úÖ Hyperparameter tuning completed!")
    logger.info(f"   Results saved: {tuning_config.results_path}")
    logger.info(f"   Best model: results/best_model.pkl")
    logger.info(f"   Clustered data: results/clustered_data.csv")
    
    return tuner


def compare_models(logger):
    """
    Mode 3: So s√°nh nhanh 4 models v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh
    """
    logger.info("\n" + "="*80)
    logger.info("MODE 3: QUICK MODEL COMPARISON")
    logger.info("="*80)
    
    evaluator = ClusteringEvaluator()
    results = []
    
    # 1. KMeans
    logger.info("\n[1/4] Testing KMeans...")
    config_kmeans = TrainingConfig(
        data_path="data/processed/encoded_data.csv",
        model_type="kmeans",
        n_clusters=5,
        model_params={"n_init": 20}
    )
    trainer = ModelTrainer(config_kmeans, evaluator)
    trainer.load_data()
    trainer.train_model()
    metrics = trainer.evaluate()
    results.append({"model": "KMeans", **metrics})
    
    # 2. GMM
    logger.info("\n[2/4] Testing GMM...")
    config_gmm = TrainingConfig(
        data_path="data/processed/encoded_data.csv",
        model_type="gmm",
        n_clusters=5,
        model_params={"covariance_type": "full"}
    )
    trainer = ModelTrainer(config_gmm, evaluator)
    trainer.load_data()
    trainer.train_model()
    metrics = trainer.evaluate()
    results.append({"model": "GMM", **metrics})
    
    # 3. DBSCAN
    logger.info("\n[3/4] Testing DBSCAN...")
    config_dbscan = TrainingConfig(
        data_path="data/processed/encoded_data.csv",
        model_type="dbscan",
        model_params={"eps": 2.0, "min_samples": 10}
    )
    trainer = ModelTrainer(config_dbscan, evaluator)
    trainer.load_data()
    trainer.train_model()
    
    labels = trainer.get_cluster_labels()
    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
    
    if n_clusters >= 2:
        metrics = trainer.evaluate()
        results.append({"model": "DBSCAN", **metrics})
    else:
        logger.warning(f"  ‚ö† DBSCAN only found {n_clusters} cluster(s), skipping evaluation")
    
    # 4. HDBSCAN
    logger.info("\n[4/4] Testing HDBSCAN...")
    try:
        config_hdbscan = TrainingConfig(
            data_path="data/processed/encoded_data.csv",
            model_type="hdbscan",
            model_params={"min_cluster_size": 15, "min_samples": 10}
        )
        trainer = ModelTrainer(config_hdbscan, evaluator)
        trainer.load_data()
        trainer.train_model()
        
        labels = trainer.get_cluster_labels()
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        
        if n_clusters >= 2:
            metrics = trainer.evaluate()
            results.append({"model": "HDBSCAN", **metrics})
        else:
            logger.warning(f"  ‚ö† HDBSCAN only found {n_clusters} cluster(s), skipping evaluation")
    except ImportError:
        logger.warning("  ‚ö† HDBSCAN not installed, skipping...")
    
    # Hi·ªÉn th·ªã b·∫£ng so s√°nh
    import pandas as pd
    df_results = pd.DataFrame(results)
    
    logger.info("\n" + "="*80)
    logger.info("üìä MODEL COMPARISON RESULTS")
    logger.info("="*80)
    print(df_results.to_string(index=False))
    
    # L∆∞u k·∫øt qu·∫£
    os.makedirs("results", exist_ok=True)
    df_results.to_csv("results/model_comparison.csv", index=False)
    logger.info(f"\nüíæ Comparison saved: results/model_comparison.csv")
    
    return df_results


def main():
    """Main function v·ªõi menu ch·ªçn mode"""
    logger = setup_logger()
    
    logger.info("\n" + "="*80)
    logger.info("üéØ HIGHLANDS COFFEE CUSTOMER SEGMENTATION")
    logger.info("="*80)
    logger.info("\nCh·ªçn mode:")
    logger.info("  1. Train single model (nhanh, test model c·ª• th·ªÉ)")
    logger.info("  2. Hyperparameter tuning (ch·∫≠m, t√¨m best config)")
    logger.info("  3. Quick model comparison (so s√°nh 4 models)")
    logger.info("  4. Run all (ch·∫°y t·∫•t c·∫£)")
    
    choice = input("\nNh·∫≠p l·ª±a ch·ªçn (1/2/3/4): ").strip()
    
    if choice == "1":
        train_single_model(logger)
    
    elif choice == "2":
        hyperparameter_tuning(logger)
    
    elif choice == "3":
        compare_models(logger)
    
    elif choice == "4":
        logger.info("\nüöÄ Running all modes...")
        train_single_model(logger)
        compare_models(logger)
        hyperparameter_tuning(logger)
    
    else:
        logger.error("‚ùå Invalid choice!")
        return
    
    logger.info("\n" + "="*80)
    logger.info("‚úÖ ALL DONE!")
    logger.info("="*80)


if __name__ == "__main__":
    main()
