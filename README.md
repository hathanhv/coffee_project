# â˜• Dá»± Ãn PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng Highlands Coffee

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

**Pipeline Machine Learning cho PhÃ¢n Cá»¥m & PhÃ¢n KhÃºc KhÃ¡ch HÃ ng**

*PhÃ¢n cá»¥m khÃ¡ch hÃ ng Highlands Coffee dá»±a trÃªn hÃ nh vi tiÃªu dÃ¹ng, nhÃ¢n kháº©u há»c vÃ  thÃ¡i Ä‘á»™ thÆ°Æ¡ng hiá»‡u*

</div>

---

## Tá»•ng Quan Dá»± Ãn

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t **pipeline ML end-to-end** Ä‘á»ƒ phÃ¢n cá»¥m khÃ¡ch hÃ ng Highlands Coffee, giÃºp:
- Nháº­n diá»‡n cÃ¡c nhÃ³m khÃ¡ch hÃ ng cÃ³ Ä‘áº·c Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
- Tá»‘i Æ°u chiáº¿n lÆ°á»£c marketing cho tá»«ng phÃ¢n khÃºc
- Hiá»ƒu sÃ¢u vá» hÃ nh vi vÃ  sá»Ÿ thÃ­ch khÃ¡ch hÃ ng
- TÃ¬m insights tá»« 3685 khÃ¡ch hÃ ng vá»›i 58+ Ä‘áº·c trÆ°ng

### TÃ­nh NÄƒng ChÃ­nh
- **4 Thuáº­t ToÃ¡n PhÃ¢n Cá»¥m**: KMeans, GMM, DBSCAN, HDBSCAN - **Code tÃ¡i sá»­ dá»¥ng cho báº¥t ká»³ model nÃ o**
- **4 Cháº¿ Äá»™ Chá»n Metric Linh Hoáº¡t**: 
  - `"silhouette"` - Tá»‘i Æ°u theo Silhouette Score
  - `"calinski_harabasz"` - Tá»‘i Æ°u theo Calinski-Harabasz Index
  - `"davies_bouldin"` - Tá»‘i Æ°u theo Davies-Bouldin Index
  - `"composite"` - CÃ¢n báº±ng cáº£ 3 metrics (máº·c Ä‘á»‹nh)
- **Pipeline TÃ¡i Sá»­ Dá»¥ng**: Chá»‰ cáº§n thay Ä‘á»•i `model_type` vÃ  `metric_selection` trong config
- **Tá»± Äá»™ng Tá»‘i Æ¯u Hyperparameter**: Grid search vá»›i 20-100+ cáº¥u hÃ¬nh cho tá»«ng model
- **Trá»±c Quan HÃ³a TÆ°Æ¡ng TÃ¡c**: PCA, t-SNE, Silhouette Analysis
- **Há»— Trá»£ Google Colab**: Train vÃ  visualize trá»±c tiáº¿p trÃªn cloud

---

## ğŸ“‚ Cáº¥u TrÃºc Dá»± Ãn

```
coffee_project/
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ raw/                                    # File CSV gá»‘c (5 datasets)
â”‚   â”‚   â”œâ”€â”€ 2017Segmentation3685case.csv        # ThÃ´ng tin nhÃ¢n kháº©u há»c khÃ¡ch hÃ ng
â”‚   â”‚   â”œâ”€â”€ Brandhealth.csv                     # Äiá»ƒm nháº­n thá»©c thÆ°Æ¡ng hiá»‡u
â”‚   â”‚   â”œâ”€â”€ Brand_Image.csv                     # ÄÃ¡nh giÃ¡ thuá»™c tÃ­nh thÆ°Æ¡ng hiá»‡u
â”‚   â”‚   â”œâ”€â”€ NeedstateDayDaypart.csv             # HÃ nh vi tiÃªu dÃ¹ng cÃ  phÃª
â”‚   â”‚   â””â”€â”€ SA#var.csv                          # Biáº¿n tÃ¢m lÃ½ khÃ¡ch hÃ ng
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ merged_full.csv                     # Dá»¯ liá»‡u Ä‘Ã£ merge 5 datasets (3685 dÃ²ng)
â”‚       â”œâ”€â”€ feature_engineering_data.csv        # Dá»¯ liá»‡u sau feature engineering
â”‚       â”œâ”€â”€ encoded_data.csv                    # Dá»¯ liá»‡u cuá»‘i cÃ¹ng Ä‘Ã£ encode cho clustering
â”‚       â””â”€â”€ cleaned/                            # CÃ¡c file Ä‘Ã£ lÃ m sáº¡ch
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ data_loader.py                      # Load & merge 5 file CSV
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py                     # Xá»­ lÃ½ missing values, outliers
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py              # Táº¡o features RFM, PPA, spending
â”‚   â”‚   â””â”€â”€ encoder.py                          # Pipeline encoding (ordinal, one-hot, scaling)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ trainer.py                          # Train 1 model (KMeans/GMM/DBSCAN/HDBSCAN)
â”‚   â”‚   â”œâ”€â”€ tuning.py                           # Grid search hyperparameter + composite scoring
â”‚   â”‚   â”œâ”€â”€ evaluator.py                        # 3 metrics: Silhouette, CH, DB
â”‚   â”‚   â””â”€â”€ save_load.py                        # LÆ°u/load model
â”‚   â”‚
â”‚   â””â”€â”€ config.py                               # Cáº¥u hÃ¬nh toÃ n cá»¥c
â”‚
â”œâ”€â”€ ğŸ“ notebooks/
â”‚   â”œâ”€â”€ EDA.ipynb                               # PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ Run_Training_Colab.ipynb                # ğŸŒŸ Notebook training chÃ­nh (Colab-ready)
â”‚   â””â”€â”€ Cluster_Visualization.ipynb             # Trá»±c quan hÃ³a & phÃ¢n tÃ­ch cá»¥m
â”‚
â”œâ”€â”€ ğŸ“ results/
â”‚   â”œâ”€â”€ *_best.pkl                              # Models tá»‘t nháº¥t (KMeans, GMM, HDBSCAN)
â”‚   â”œâ”€â”€ *_labels.csv                            # Káº¿t quáº£ gÃ¡n nhÃ£n cá»¥m
â”‚   â”œâ”€â”€ *_tuning.csv                            # Káº¿t quáº£ grid search
â”‚   â”œâ”€â”€ cluster_profiling.csv                   # Äáº·c Ä‘iá»ƒm tá»«ng cá»¥m
â”‚   â””â”€â”€ *.png                                   # HÃ¬nh áº£nh trá»±c quan (PCA, t-SNE, silhouette)
â”‚
â”œâ”€â”€ main.py                                     # Giao diá»‡n CLI (4 cháº¿ Ä‘á»™)
â”œâ”€â”€ requirements.txt                            # ThÆ° viá»‡n phá»¥ thuá»™c
â””â”€â”€ README.md                                   # File nÃ y
```

---

## ğŸ”„ Pipeline Machine Learning

```mermaid
graph LR
    A[Dá»¯ Liá»‡u Gá»‘c<br/>5 File CSV] --> B[LÃ m Sáº¡ch Dá»¯ Liá»‡u]
    B --> C[Feature Engineering<br/>RFM, PPA, Spending]
    C --> D[Pipeline Encoding<br/>Ordinal + OneHot + Scaling]
    D --> E[Models PhÃ¢n Cá»¥m<br/>KMeans, GMM, DBSCAN, HDBSCAN]
    E --> F[ÄÃ¡nh GiÃ¡ Composite Metric<br/>Sil + CH + DB]
    F --> G[Chá»n Model Tá»‘t Nháº¥t]
    G --> H[PhÃ¢n TÃ­ch Äáº·c Äiá»ƒm Cá»¥m]
    H --> I[Trá»±c Quan HÃ³a<br/>PCA, t-SNE, Silhouette]
```

### CÃ¡c BÆ°á»›c Trong Pipeline

#### 1ï¸âƒ£ **Load & LÃ m Sáº¡ch Dá»¯ Liá»‡u** (`src/preprocessing/`)
```python
from src.preprocessing.data_loader import DataLoader
from src.preprocessing.data_cleaner import DataCleaner

# Load 5 file CSV
loader = DataLoader(use_cleaned=True)
loader.load_all_files()
df_merged = loader.merge_all()  # 3685 dÃ²ng Ã— 100+ cá»™t

# LÃ m sáº¡ch dá»¯ liá»‡u
cleaner = DataCleaner()
df_clean = cleaner.handle_missing_values(df_merged)
```

**Äáº§u vÃ o**: 5 file CSV gá»‘c  
**Äáº§u ra**: `merged_full.csv` (3685 máº«u, 100+ Ä‘áº·c trÆ°ng)

#### 2ï¸âƒ£ **Feature Engineering** (`src/preprocessing/feature_engineering.py`)
```python
from src.preprocessing.feature_engineering import FeatureEngineer

engineer = FeatureEngineer()
df_features = engineer.create_rfm_features(df_clean)      # Recency, Frequency, Monetary
df_features = engineer.create_ppa_features(df_features)   # Price Per Action (GiÃ¡/HÃ nh Ä‘á»™ng)
df_features = engineer.aggregate_spending(df_features)    # Tá»•ng chi tiÃªu
```

**CÃ¡c Äáº·c TrÆ°ng ÄÆ°á»£c Táº¡o**:
- **RFM Metrics**: Recency (gáº§n Ä‘Ã¢y), Frequency (táº§n suáº¥t), Monetary (giÃ¡ trá»‹)
- **Máº«u Chi TiÃªu**: Tá»•ng, Trung bÃ¬nh, Max chi tiÃªu
- **Thá»i Gian**: Táº§n suáº¥t ghÃ© thÄƒm, thá»i gian tá»« láº§n cuá»‘i
- **HÃ nh Vi**: LÃ²ng trung thÃ nh thÆ°Æ¡ng hiá»‡u, sá»Ÿ thÃ­ch sáº£n pháº©m

**Äáº§u ra**: `feature_engineering_data.csv`

#### 3ï¸âƒ£ **Encode Data** (`src/preprocessing/encoder.py`)
```python
from src.preprocessing.encoder import FeatureEncoder

encoder = FeatureEncoder()
X_encoded = encoder.fit_transform(df_features)
```

**Chiáº¿n LÆ°á»£c MÃ£ HÃ³a**:
- **Numeric (lá»‡ch)**: Log-transform â†’ Standard scaling
- **Numeric (chuáº©n)**: Standard scaling
- **Ordinal**: NhÃ³m tuá»•i, Má»©c Ä‘á»™ hiá»ƒu biáº¿t
- **Categorical**: One-hot encoding (ThÃ nh phá»‘, Giá»›i tÃ­nh, Nghá» nghiá»‡p)

**Äáº§u ra**: `encoded_data.csv` (3685 Ã— 58 Ä‘áº·c trÆ°ng, Ä‘Ã£ chuáº©n hÃ³a)

#### 4ï¸âƒ£ **Train Model** (`src/models/trainer.py`)
```python
from src.models.trainer import ModelTrainer, TrainingConfig

config = TrainingConfig(
    data_path="data/processed/encoded_data.csv",
    model_type="kmeans",
    n_clusters=5,
    model_params={"n_init": 20, "max_iter": 500}
)

trainer = ModelTrainer(config=config)
trainer.load_data()
trainer.train_model()
metrics = trainer.evaluate()  # Silhouette, Calinski-Harabasz, Davies-Bouldin
```

**CÃ¡c Model Há»— Trá»£**:
| Model | PhÃ¹ Há»£p Vá»›i | Tham Sá»‘ Tá»‘i Æ¯u |
|-------|----------|--------------|
| **KMeans** | Cá»¥m hÃ¬nh cáº§u, biáº¿t trÆ°á»›c sá»‘ cá»¥m K | n_clusters (3-7), n_init, max_iter |
| **GMM** | Cá»¥m chá»“ng láº¥p, xÃ¡c suáº¥t | n_clusters (3-7), covariance_type |
| **DBSCAN** | HÃ¬nh dáº¡ng tÃ¹y Ã½, phÃ¡t hiá»‡n nhiá»…u | eps (0.5-5.0), min_samples (5-20) |
| **HDBSCAN** | Máº­t Ä‘á»™ thay Ä‘á»•i, tá»± Ä‘á»™ng tÃ¬m K | min_cluster_size (10-100), min_samples, metric |

#### 5ï¸âƒ£ **Tá»‘i Æ¯u Hyperparameter** (`src/models/tuning.py`)

**ğŸ¯ 4 Cháº¿ Äá»™ Chá»n Metric - Linh Hoáº¡t Cho Má»i Model:**

```python
from src.models.tuning import HyperparameterTuner, TuningConfig

# Cháº¿ Ä‘á»™ 1: Composite Score (KhuyÃªn dÃ¹ng - cÃ¢n báº±ng cáº£ 3 metrics)
config_composite = TuningConfig(
    metric_selection="composite",
    silhouette_weight=0.4,
    calinski_weight=0.3,
    davies_weight=0.3
)

# Cháº¿ Ä‘á»™ 2: Chá»‰ Silhouette
config_sil = TuningConfig(metric_selection="silhouette")

# Cháº¿ Ä‘á»™ 3: Chá»‰ Calinski-Harabasz
config_ch = TuningConfig(metric_selection="calinski_harabasz")

# Cháº¿ Ä‘á»™ 4: Chá»‰ Davies-Bouldin
config_db = TuningConfig(metric_selection="davies_bouldin")

# Sá»­ dá»¥ng vá»›i Báº¤T Ká»² model nÃ o (KMeans, GMM, DBSCAN, HDBSCAN)
tuner = HyperparameterTuner(config=config_composite)
```

**CÃ´ng Thá»©c Composite Score**:
```
Composite = 0.4 Ã— Silhouette_norm + 0.3 Ã— CH_norm + 0.3 Ã— (1 - DB_norm)
```
Trong Ä‘Ã³:
- **Silhouette** (0-1): Cao hÆ¡n = phÃ¢n tÃ¡ch tá»‘t hÆ¡n
- **Calinski-Harabasz** (Ä‘Ã£ chuáº©n hÃ³a): Cao hÆ¡n = cá»¥m rÃµ rÃ ng hÆ¡n
- **Davies-Bouldin** (Ä‘áº£o ngÆ°á»£c & chuáº©n hÃ³a): Tháº¥p hÆ¡n = cá»¥m compact hÆ¡n

**Táº¡i Sao DÃ¹ng Composite?**: Metric Ä‘Æ¡n láº» cÃ³ thá»ƒ gÃ¢y nháº§m láº«n (VD: silhouette cao nhÆ°ng phÃ¢n cá»¥m máº¥t cÃ¢n báº±ng). Composite score Ä‘áº£m báº£o:

âœ… PhÃ¢n tÃ¡ch tá»‘t (Silhouette)  
âœ… Tá»· lá»‡ phÆ°Æ¡ng sai cao (Calinski-Harabasz)  
âœ… Cá»¥m compact (Davies-Bouldin)

#### 6ï¸âƒ£ **PhÃ¢n TÃ­ch Äáº·c Äiá»ƒm Cá»¥m** (`notebooks/Cluster_Visualization.ipynb`)
```python
# PhÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm cá»§a tá»«ng cá»¥m
for cluster_id in range(n_clusters):
    cluster_data = df[df['cluster'] == cluster_id]
    
    # Há»“ sÆ¡ nhÃ¢n kháº©u há»c
    print(f"Tuá»•i TB: {cluster_data['age'].mean():.1f}")
    print(f"Giá»›i tÃ­nh: {cluster_data['gender'].mode()[0]}")
    
    # Há»“ sÆ¡ hÃ nh vi
    print(f"Chi tiÃªu TB: {cluster_data['total_spending'].mean():.2f}Ä‘")
    print(f"Táº§n suáº¥t ghÃ©: {cluster_data['visit_freq'].mean():.1f} láº§n/thÃ¡ng")
```

**Äáº§u ra**: `results/cluster_profiling.csv`

---

## ğŸŒŸ Usage

### CÃ¡ch 1: Cháº¡y Local

```bash
# 1. Clone repo
git clone <repo-url>
cd coffee_project

# 2. CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

# 3. Cháº¡y pipeline chÃ­nh
python main.py
```

**CÃ¡c Cháº¿ Äá»™ Trong Main.py**:
```
[1] Train Single Model      - Train KMeans/GMM/DBSCAN/HDBSCAN vá»›i config cá»‘ Ä‘á»‹nh
[2] Hyperparameter Tuning   - Grid search tÃ¬m tham sá»‘ tá»‘i Æ°u
[3] Quick Comparison        - So sÃ¡nh nhanh 4 models
[4] Run All                 - Cháº¡y toÃ n bá»™ pipeline
```

### CÃ¡ch 2: Google Colab

**Má»Ÿ file**: `notebooks/Run_Training_Colab.ipynb`

```python
# Cell 1: Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Cell 2: Chuyá»ƒn Ä‘áº¿n thÆ° má»¥c project
%cd "/content/drive/MyDrive/coffee_project"

# Cell 3: So SÃ¡nh Nhanh
# So sÃ¡nh 4 models: KMeans, GMM, DBSCAN, HDBSCAN

# Cell 5B: HDBSCAN Tuning (Composite Score)
# Grid search vá»›i 20-30 cáº¥u hÃ¬nh, tá»± Ä‘á»™ng chá»n model tá»‘t nháº¥t

# Cell 5C: GMM Tuning (Composite Score)
# Test 20 cáº¥u hÃ¬nh (5 n_clusters Ã— 4 covariance types)
```

**Trá»±c Quan HÃ³a**: `notebooks/Cluster_Visualization.ipynb`
- Biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n PCA 2D/3D
- Trá»±c quan hÃ³a t-SNE
- PhÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm cá»¥m (nhÃ¢n kháº©u há»c, hÃ nh vi)

---

## ğŸ“Š Káº¿t Quáº£

### So SÃ¡nh CÃ¡c Model

| Model | Silhouette â†‘ | Calinski-Harabasz â†‘ | Davies-Bouldin â†“ | Composite Score â†‘ | Sá»‘ Cá»¥m |
|-------|-------------|---------------------|------------------|-------------------|----------|
| **KMeans** | **0.25** | **1269.2** | **1.53** | **0.70** | 3 | 
| **GMM** | 0.25 | 1269.2 | 1.53 | 0.67 | 3 | XÃ¡c suáº¥t, cá»¥m chá»“ng láº¥p |
| **DBSCAN** | 0.26 | 735.4 | 2.21 | 0.42 | 5 | 
| **HDBSCAN** | 0.50 | 96.5 | 0.51 | 0.50 | 3 |

### ğŸ† Model Tá»‘t Nháº¥t: KMeans

**Hyperparameters Tá»‘i Æ¯u**:
```python
{
    "n_clusters": 3,
    "n_init": 10,
    "init" : "k-means++",
    "max_iter": 300
}
```

**PhÃ¢n bá»‘ cÃ¢n báº±ng**: Má»—i cá»¥m chiáº¿m 18-22% tá»•ng sá»‘ khÃ¡ch hÃ ng, khÃ´ng cÃ³ cá»¥m quÃ¡ nhá» (<10%)

### HÃ¬nh áº¢nh Trá»±c Quan

#### Trá»±c Quan HÃ³a PCA
![Biá»ƒu Ä‘á»“ PCA](results/cluster_pca.png)
*Chiáº¿u PCA 2D cho tháº¥y sá»± phÃ¢n tÃ¡ch rÃµ rÃ ng giá»¯a cÃ¡c cá»¥m*

#### Trá»±c Quan HÃ³a t-SNE
![Biá»ƒu Ä‘á»“ t-SNE](results/cluster_tsne.png)
*t-SNE embedding tiáº¿t lá»™ cáº¥u trÃºc cá»¥c bá»™*

#### PhÃ¢n Bá»‘ Cá»¥m
![PhÃ¢n bá»‘](results/cluster_distribution.png)
*KÃ­ch thÆ°á»›c cá»¥m cÃ¢n báº±ng (khÃ´ng cá»¥m nÃ o < 10%)*

---

## TÃ­nh NÄƒng Ná»•i Báº­t: Code TÃ¡i Sá»­ Dá»¥ng & Linh Hoáº¡t

### â™»ï¸ Pipeline CÃ³ Thá»ƒ TÃ¡i Sá»­ Dá»¥ng 100%

Code Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ **dá»… dÃ ng thay Ä‘á»•i model vÃ  metric selection** mÃ  khÃ´ng cáº§n sá»­a logic:

```python
# Chá»‰ cáº§n thay Ä‘á»•i 2 tham sá»‘ nÃ y!
config = TuningConfig(
    metric_selection="composite",  # Äá»•i: "silhouette", "calinski_harabasz", "davies_bouldin"
    model_type="kmeans"            # Äá»•i: "gmm", "dbscan", "hdbscan"
)

# Code cÃ²n láº¡i giá»¯ nguyÃªn
tuner = HyperparameterTuner(config=config)
tuner.run_grid_search(model_type, grid_params)
tuner.save_results()
```

### ğŸ›ï¸ 4 Cháº¿ Äá»™ Metric Selection

| Cháº¿ Äá»™ | Khi NÃ o DÃ¹ng | Æ¯u Äiá»ƒm |
|--------|--------------|----------|
| `"silhouette"` | Muá»‘n cá»¥m phÃ¢n tÃ¡ch rÃµ rÃ ng | ÄÆ¡n giáº£n, trá»±c quan, range 0-1 |
| `"calinski_harabasz"` | Muá»‘n cá»¥m compact, variance cao | Tá»‘t cho K-means style clustering |
| `"davies_bouldin"` | Muá»‘n minimize overlap giá»¯a cá»¥m | Penalty cho cá»¥m gáº§n nhau |
| `"composite"` | **KhuyÃªn dÃ¹ng** - cÃ¢n báº±ng táº¥t cáº£ | Robust, trÃ¡nh bias vÃ o 1 metric |



---

</div>
