{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a371a58c",
      "metadata": {
        "id": "a371a58c"
      },
      "source": [
        "## 1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2e59cbc2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e59cbc2",
        "outputId": "12e14abf-1c55-4cf4-cd02-23d824f867ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "505c3854",
      "metadata": {
        "id": "505c3854"
      },
      "source": [
        "## 2. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6733b01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6733b01a",
        "outputId": "bd350c2d-c433-4610-c3f0-800e294888ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ƒê·ªì √°n Python/coffee_project\n",
            "‚úÖ Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c project\n",
        "%cd \"/content/drive/MyDrive/ƒê·ªì √°n Python/coffee_project\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', module='sklearn')\n",
        "\n",
        "# Import libraries\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "from src.models.trainer import ModelTrainer, TrainingConfig\n",
        "from src.models.evaluator import ClusteringEvaluator\n",
        "from src.models.tuning import HyperparameterTuner, TuningConfig\n",
        "import pandas as pd\n",
        "import logging\n",
        "\n",
        "# Setup logger\n",
        "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8abe14",
      "metadata": {
        "id": "1d8abe14"
      },
      "source": [
        "## 3. Hyperparameter Tuning (Advanced)\n",
        "Grid search t·∫•t c·∫£ models ƒë·ªÉ t√¨m best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "OyN5voMkjMo5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyN5voMkjMo5",
        "outputId": "f4fb6cf1-6527-48c2-b7d0-82db70100492"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üìÇ Loading data for tuning from data/processed/encoded_data.csv...\n",
            "  ‚úì Data loaded: (3685, 58)\n",
            "\n",
            "üöÄ Starting Grid Search for: KMEANS\n",
            "  Total combinations to test: 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "K-MEANS HYPERPARAMETER TUNING\n",
            "================================================================================\n",
            "Grid parameters:\n",
            "  n_clusters: [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "  init: ['k-means++']\n",
            "  n_init: [10, 20]\n",
            "  max_iter: [300]\n",
            "\n",
            "Total combinations: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  [1/16] KMEANS_n_clusters3_initk-means++_n_init10_max_iter300: Sil=0.2544, CH=1269.22, DB=1.5338, Clusters=3\n",
            "  [2/16] KMEANS_n_clusters3_initk-means++_n_init20_max_iter300: Sil=0.2544, CH=1269.22, DB=1.5338, Clusters=3\n",
            "  [3/16] KMEANS_n_clusters4_initk-means++_n_init10_max_iter300: Sil=0.2355, CH=1030.48, DB=1.8631, Clusters=4\n",
            "  [4/16] KMEANS_n_clusters4_initk-means++_n_init20_max_iter300: Sil=0.2355, CH=1030.48, DB=1.8631, Clusters=4\n",
            "  [5/16] KMEANS_n_clusters5_initk-means++_n_init10_max_iter300: Sil=0.2352, CH=894.63, DB=1.7419, Clusters=5\n",
            "  [6/16] KMEANS_n_clusters5_initk-means++_n_init20_max_iter300: Sil=0.2352, CH=894.63, DB=1.7419, Clusters=5\n",
            "  [7/16] KMEANS_n_clusters6_initk-means++_n_init10_max_iter300: Sil=0.1937, CH=820.04, DB=1.8492, Clusters=6\n",
            "  [8/16] KMEANS_n_clusters6_initk-means++_n_init20_max_iter300: Sil=0.1938, CH=820.06, DB=1.8499, Clusters=6\n",
            "  [9/16] KMEANS_n_clusters7_initk-means++_n_init10_max_iter300: Sil=0.2019, CH=777.00, DB=1.6383, Clusters=7\n",
            "  [10/16] KMEANS_n_clusters7_initk-means++_n_init20_max_iter300: Sil=0.2019, CH=777.00, DB=1.6383, Clusters=7\n",
            "  [11/16] KMEANS_n_clusters8_initk-means++_n_init10_max_iter300: Sil=0.1877, CH=733.05, DB=1.6986, Clusters=8\n",
            "  [12/16] KMEANS_n_clusters8_initk-means++_n_init20_max_iter300: Sil=0.1877, CH=733.05, DB=1.6986, Clusters=8\n",
            "  [13/16] KMEANS_n_clusters9_initk-means++_n_init10_max_iter300: Sil=0.1758, CH=634.24, DB=1.8417, Clusters=9\n",
            "  [14/16] KMEANS_n_clusters9_initk-means++_n_init20_max_iter300: Sil=0.1736, CH=675.62, DB=1.7268, Clusters=9\n",
            "  [15/16] KMEANS_n_clusters10_initk-means++_n_init10_max_iter300: Sil=0.1800, CH=630.41, DB=1.7713, Clusters=10\n",
            "  [16/16] KMEANS_n_clusters10_initk-means++_n_init20_max_iter300: Sil=0.1894, CH=643.43, DB=1.6917, Clusters=10\n",
            "\n",
            "üíæ Tuning results saved to: results/kmeans_tuning.csv\n",
            "\n",
            "üèÜ TOP 3 MODELS:\n",
            "‚úì ModelTrainer initialized\n",
            "  Model type: kmeans\n",
            "  Data path: data/processed/encoded_data.csv\n",
            "üìÇ Loading data from data/processed/encoded_data.csv...\n",
            "  ‚úì Data loaded: 3685 samples, 58 features\n",
            "üîß Training KMEANS with 3 clusters...\n",
            "  ‚úì Model trained successfully\n",
            "üíæ Model saved: results/kmeans_best.pkl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_type  n_clusters  silhouette  calinski_harabasz  davies_bouldin\n",
            "    kmeans           3    0.254433        1269.217570        1.533831\n",
            "    kmeans           3    0.254433        1269.217570        1.533831\n",
            "    kmeans           4    0.235535        1030.477913        1.863101\n",
            "\n",
            "================================================================================\n",
            "üèÜ BEST K-MEANS CONFIG\n",
            "================================================================================\n",
            "  n_clusters             : 3\n",
            "  init                   : k-means++\n",
            "  n_init                 : 10\n",
            "\n",
            "  Silhouette Score       : 0.2544\n",
            "  Calinski-Harabasz      : 1269.22\n",
            "  Davies-Bouldin Index   : 1.5338\n",
            "\n",
            "üîÑ Training best model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üíæ Labels saved: results/kmeans_best_labels.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best K-Means model saved!\n",
            "   Model: results/kmeans_best.pkl\n",
            "   Labels: results/kmeans_best_labels.csv\n",
            "\n",
            "================================================================================\n",
            "üìä TOP 5 CONFIGS\n",
            "================================================================================\n",
            " n_clusters      init  n_init  silhouette  calinski_harabasz  davies_bouldin\n",
            "          3 k-means++      10    0.254433        1269.217570        1.533831\n",
            "          3 k-means++      20    0.254433        1269.217570        1.533831\n",
            "          4 k-means++      10    0.235535        1030.477913        1.863101\n",
            "          4 k-means++      20    0.235535        1030.477913        1.863101\n",
            "          5 k-means++      10    0.235202         894.634671        1.741909\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"K-MEANS HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Thi·∫øt l·∫≠p Grid cho K-Means\n",
        "# n_clusters: S·ªë l∆∞·ª£ng c·ª•m mu·ªën th·ª≠ (quan tr·ªçng nh·∫•t)\n",
        "# init: Ph∆∞∆°ng ph√°p kh·ªüi t·∫°o t√¢m c·ª•m\n",
        "# n_init: S·ªë l·∫ßn ch·∫°y thu·∫≠t to√°n v·ªõi c√°c t√¢m ng·∫´u nhi√™n kh√°c nhau\n",
        "kmeans_grid = {\n",
        "    \"n_clusters\": [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    \"init\": [\"k-means++\"],\n",
        "    \"n_init\": [10, 20],\n",
        "    \"max_iter\": [300]\n",
        "}\n",
        "\n",
        "print(\"Grid parameters:\")\n",
        "for key, values in kmeans_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "\n",
        "total = 1\n",
        "for v in kmeans_grid.values():\n",
        "    total *= len(v)\n",
        "print(f\"\\nTotal combinations: {total}\")\n",
        "\n",
        "# 2. Kh·ªüi t·∫°o Tuner\n",
        "evaluator = ClusteringEvaluator()\n",
        "tuning_config = TuningConfig(\n",
        "    data_path=\"data/processed/encoded_data.csv\",\n",
        "    results_path=\"results/kmeans_tuning.csv\",  # ƒê·ªïi t√™n file l∆∞u\n",
        "    metric_selection=\"silhouette\"              # Metric ch√≠nh ƒë·ªÉ ch·ªçn model\n",
        ")\n",
        "tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)\n",
        "\n",
        "# 3. Ch·∫°y Tuning\n",
        "# L∆∞u √Ω: \"kmeans\" ph·∫£i kh·ªõp v·ªõi t√™n model trong ModelTrainer\n",
        "tuner.run_grid_search(\"kmeans\", kmeans_grid)\n",
        "\n",
        "# 4. L∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p\n",
        "tuner.save_results()\n",
        "\n",
        "# 5. L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t v√† Train l·∫°i\n",
        "df_results = tuner.get_summary()\n",
        "\n",
        "if len(df_results) > 0:\n",
        "    best = df_results.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üèÜ BEST K-MEANS CONFIG\")\n",
        "    print(\"=\"*80)\n",
        "    # Hi·ªÉn th·ªã c√°c tham s·ªë c·ªßa K-Means\n",
        "    print(f\"  n_clusters             : {int(best['n_clusters'])}\")\n",
        "    print(f\"  init                   : {best['init']}\")\n",
        "    print(f\"  n_init                 : {best['n_init']}\")\n",
        "\n",
        "    print(f\"\\n  Silhouette Score       : {best['silhouette']:.4f}\")\n",
        "    print(f\"  Calinski-Harabasz      : {best['calinski_harabasz']:.2f}\")\n",
        "    print(f\"  Davies-Bouldin Index   : {best['davies_bouldin']:.4f}\")\n",
        "\n",
        "    # Train v√† l∆∞u model t·ªët nh·∫•t\n",
        "    print(\"\\nüîÑ Training best model...\")\n",
        "\n",
        "    # Chu·∫©n b·ªã params (n_clusters th∆∞·ªùng ƒë∆∞·ª£c t√°ch ri√™ng trong logic c·ªßa trainer)\n",
        "    best_params = {\n",
        "        \"init\": best['init'],\n",
        "        \"n_init\": int(best['n_init']),\n",
        "        \"max_iter\": int(best['max_iter'])\n",
        "    }\n",
        "\n",
        "    config = TrainingConfig(\n",
        "        data_path=\"data/processed/encoded_data.csv\",\n",
        "        model_type=\"kmeans\",\n",
        "        n_clusters=int(best['n_clusters']), # Quan tr·ªçng: KMeans c·∫ßn n_clusters\n",
        "        model_params=best_params,\n",
        "        model_path=\"results/kmeans_best.pkl\"\n",
        "    )\n",
        "\n",
        "    trainer = ModelTrainer(config=config, evaluator=evaluator)\n",
        "    trainer.load_data()\n",
        "    trainer.train_model()\n",
        "    trainer.save_model()\n",
        "    trainer.save_labels(\"results/kmeans_best_labels.csv\")\n",
        "\n",
        "    print(\"‚úÖ Best K-Means model saved!\")\n",
        "    print(\"   Model: results/kmeans_best.pkl\")\n",
        "    print(\"   Labels: results/kmeans_best_labels.csv\")\n",
        "\n",
        "    # Show top 5 configs\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä TOP 5 CONFIGS\")\n",
        "    print(\"=\"*80)\n",
        "    # Ch·ªâ ch·ªçn c√°c c·ªôt c√≥ √Ω nghƒ©a v·ªõi K-Means\n",
        "    cols = ['n_clusters', 'init', 'n_init',\n",
        "            'silhouette', 'calinski_harabasz', 'davies_bouldin']\n",
        "    # L·ªçc c√°c c·ªôt th·ª±c s·ª± t·ªìn t·∫°i trong df k·∫øt qu·∫£ (ƒë·ªÅ ph√≤ng l·ªói key)\n",
        "    cols = [c for c in cols if c in df_results.columns]\n",
        "    print(df_results[cols].head(5).to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid results found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "uE4nnWKkj2Nr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE4nnWKkj2Nr",
        "outputId": "16035663-fd32-4ca4-cfde-3de4ddd09e85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üìÇ Loading data for tuning from data/processed/encoded_data.csv...\n",
            "  ‚úì Data loaded: (3685, 58)\n",
            "\n",
            "üöÄ Starting Grid Search for: KMEANS\n",
            "  Total combinations to test: 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "K-MEANS HYPERPARAMETER TUNING\n",
            "================================================================================\n",
            "Grid parameters:\n",
            "  n_clusters: [3, 4, 5, 6, 7, 8, 9, 10]\n",
            "  init: ['k-means++']\n",
            "  n_init: [10, 20]\n",
            "  max_iter: [300]\n",
            "\n",
            "Total combinations: 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  [1/16] KMEANS_n_clusters3_initk-means++_n_init10_max_iter300: Sil=0.2544, CH=1269.22, DB=1.5338, Clusters=3\n",
            "  [2/16] KMEANS_n_clusters3_initk-means++_n_init20_max_iter300: Sil=0.2544, CH=1269.22, DB=1.5338, Clusters=3\n",
            "  [3/16] KMEANS_n_clusters4_initk-means++_n_init10_max_iter300: Sil=0.2355, CH=1030.48, DB=1.8631, Clusters=4\n",
            "  [4/16] KMEANS_n_clusters4_initk-means++_n_init20_max_iter300: Sil=0.2355, CH=1030.48, DB=1.8631, Clusters=4\n",
            "  [5/16] KMEANS_n_clusters5_initk-means++_n_init10_max_iter300: Sil=0.2352, CH=894.63, DB=1.7419, Clusters=5\n",
            "  [6/16] KMEANS_n_clusters5_initk-means++_n_init20_max_iter300: Sil=0.2352, CH=894.63, DB=1.7419, Clusters=5\n",
            "  [7/16] KMEANS_n_clusters6_initk-means++_n_init10_max_iter300: Sil=0.1937, CH=820.04, DB=1.8492, Clusters=6\n",
            "  [8/16] KMEANS_n_clusters6_initk-means++_n_init20_max_iter300: Sil=0.1938, CH=820.06, DB=1.8499, Clusters=6\n",
            "  [9/16] KMEANS_n_clusters7_initk-means++_n_init10_max_iter300: Sil=0.2019, CH=777.00, DB=1.6383, Clusters=7\n",
            "  [10/16] KMEANS_n_clusters7_initk-means++_n_init20_max_iter300: Sil=0.2019, CH=777.00, DB=1.6383, Clusters=7\n",
            "  [11/16] KMEANS_n_clusters8_initk-means++_n_init10_max_iter300: Sil=0.1877, CH=733.05, DB=1.6986, Clusters=8\n",
            "  [12/16] KMEANS_n_clusters8_initk-means++_n_init20_max_iter300: Sil=0.1877, CH=733.05, DB=1.6986, Clusters=8\n",
            "  [13/16] KMEANS_n_clusters9_initk-means++_n_init10_max_iter300: Sil=0.1758, CH=634.24, DB=1.8417, Clusters=9\n",
            "  [14/16] KMEANS_n_clusters9_initk-means++_n_init20_max_iter300: Sil=0.1736, CH=675.62, DB=1.7268, Clusters=9\n",
            "  [15/16] KMEANS_n_clusters10_initk-means++_n_init10_max_iter300: Sil=0.1800, CH=630.41, DB=1.7713, Clusters=10\n",
            "  [16/16] KMEANS_n_clusters10_initk-means++_n_init20_max_iter300: Sil=0.1894, CH=643.43, DB=1.6917, Clusters=10\n",
            "\n",
            "üíæ Tuning results saved to: results/kmeans_composite_tuning.csv\n",
            "\n",
            "üèÜ TOP 3 MODELS:\n",
            "\n",
            "‚úÖ Best model updated based on composite score: kmeans\n",
            "‚úì ModelTrainer initialized\n",
            "  Model type: kmeans\n",
            "  Data path: data/processed/encoded_data.csv\n",
            "üìÇ Loading data from data/processed/encoded_data.csv...\n",
            "  ‚úì Data loaded: 3685 samples, 58 features\n",
            "üîß Training KMEANS with 3 clusters...\n",
            "  ‚úì Model trained successfully\n",
            "üíæ Model saved: results/kmeans_composite_best.pkl\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_type  n_clusters  silhouette  calinski_harabasz  davies_bouldin  composite_score\n",
            "    kmeans           3    0.254433        1269.217570        1.533831         0.701773\n",
            "    kmeans           3    0.254433        1269.217570        1.533831         0.701773\n",
            "    kmeans           7    0.201851         776.998807        1.638289         0.354408\n",
            "\n",
            "================================================================================\n",
            "üèÜ BEST K-MEANS CONFIG\n",
            "================================================================================\n",
            "  n_clusters             : 3\n",
            "  init                   : k-means++\n",
            "  n_init                 : 10\n",
            "\n",
            "  Silhouette Score       : 0.2544\n",
            "  Calinski-Harabasz      : 1269.22\n",
            "  Davies-Bouldin Index   : 1.5338\n",
            "\n",
            "üîÑ Training best model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "üíæ Labels saved: results/kmeans_best_composite_labels.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Best K-Means model saved!\n",
            "   Model: results/kmeans_composite_best.pkl\n",
            "   Labels: results/kmeans_best_composite_labels.csv\n",
            "\n",
            "================================================================================\n",
            "üìä TOP 5 CONFIGS\n",
            "================================================================================\n",
            " n_clusters      init  n_init  silhouette  calinski_harabasz  davies_bouldin\n",
            "          3 k-means++      10    0.254433        1269.217570        1.533831\n",
            "          3 k-means++      20    0.254433        1269.217570        1.533831\n",
            "          7 k-means++      20    0.201851         776.998807        1.638289\n",
            "          7 k-means++      10    0.201851         776.998807        1.638289\n",
            "          5 k-means++      20    0.235202         894.634671        1.741909\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"K-MEANS HYPERPARAMETER TUNING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Thi·∫øt l·∫≠p Grid cho K-Means\n",
        "# n_clusters: S·ªë l∆∞·ª£ng c·ª•m mu·ªën th·ª≠ (quan tr·ªçng nh·∫•t)\n",
        "# init: Ph∆∞∆°ng ph√°p kh·ªüi t·∫°o t√¢m c·ª•m\n",
        "# n_init: S·ªë l·∫ßn ch·∫°y thu·∫≠t to√°n v·ªõi c√°c t√¢m ng·∫´u nhi√™n kh√°c nhau\n",
        "kmeans_grid = {\n",
        "    \"n_clusters\": [3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    \"init\": [\"k-means++\"],\n",
        "    \"n_init\": [10, 20],\n",
        "    \"max_iter\": [300]\n",
        "}\n",
        "\n",
        "print(\"Grid parameters:\")\n",
        "for key, values in kmeans_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "\n",
        "total = 1\n",
        "for v in kmeans_grid.values():\n",
        "    total *= len(v)\n",
        "print(f\"\\nTotal combinations: {total}\")\n",
        "\n",
        "# 2. Kh·ªüi t·∫°o Tuner\n",
        "evaluator = ClusteringEvaluator()\n",
        "tuning_config = TuningConfig(\n",
        "    data_path=\"data/processed/encoded_data.csv\",\n",
        "    results_path=\"results/kmeans_composite_tuning.csv\",\n",
        "    metric_selection=\"composite\",\n",
        "    silhouette_weight=0.4,\n",
        "    calinski_weight=0.3,\n",
        "    davies_weight=0.3\n",
        ")\n",
        "tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)\n",
        "\n",
        "# 3. Ch·∫°y Tuning\n",
        "# L∆∞u √Ω: \"kmeans\" ph·∫£i kh·ªõp v·ªõi t√™n model trong ModelTrainer\n",
        "tuner.run_grid_search(\"kmeans\", kmeans_grid)\n",
        "\n",
        "# 4. L∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p\n",
        "tuner.save_results()\n",
        "\n",
        "# 5. L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t v√† Train l·∫°i\n",
        "df_results = tuner.get_summary()\n",
        "\n",
        "if len(df_results) > 0:\n",
        "    best = df_results.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üèÜ BEST K-MEANS CONFIG\")\n",
        "    print(\"=\"*80)\n",
        "    # Hi·ªÉn th·ªã c√°c tham s·ªë c·ªßa K-Means\n",
        "    print(f\"  n_clusters             : {int(best['n_clusters'])}\")\n",
        "    print(f\"  init                   : {best['init']}\")\n",
        "    print(f\"  n_init                 : {best['n_init']}\")\n",
        "\n",
        "    print(f\"\\n  Silhouette Score       : {best['silhouette']:.4f}\")\n",
        "    print(f\"  Calinski-Harabasz      : {best['calinski_harabasz']:.2f}\")\n",
        "    print(f\"  Davies-Bouldin Index   : {best['davies_bouldin']:.4f}\")\n",
        "\n",
        "    # Train v√† l∆∞u model t·ªët nh·∫•t\n",
        "    print(\"\\nüîÑ Training best model...\")\n",
        "\n",
        "    # Chu·∫©n b·ªã params (n_clusters th∆∞·ªùng ƒë∆∞·ª£c t√°ch ri√™ng trong logic c·ªßa trainer)\n",
        "    best_params = {\n",
        "        \"init\": best['init'],\n",
        "        \"n_init\": int(best['n_init']),\n",
        "        \"max_iter\": int(best['max_iter'])\n",
        "    }\n",
        "\n",
        "    config = TrainingConfig(\n",
        "        data_path=\"data/processed/encoded_data.csv\",\n",
        "        model_type=\"kmeans\",\n",
        "        n_clusters=int(best['n_clusters']), # Quan tr·ªçng: KMeans c·∫ßn n_clusters\n",
        "        model_params=best_params,\n",
        "        model_path=\"results/kmeans_composite_best.pkl\"\n",
        "    )\n",
        "\n",
        "    trainer = ModelTrainer(config=config, evaluator=evaluator)\n",
        "    trainer.load_data()\n",
        "    trainer.train_model()\n",
        "    trainer.save_model()\n",
        "    trainer.save_labels(\"results/kmeans_best_composite_labels.csv\")\n",
        "\n",
        "    print(\"‚úÖ Best K-Means model saved!\")\n",
        "    print(\"   Model: results/kmeans_composite_best.pkl\")\n",
        "    print(\"   Labels: results/kmeans_best_composite_labels.csv\")\n",
        "\n",
        "    # Show top 5 configs\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä TOP 5 CONFIGS\")\n",
        "    print(\"=\"*80)\n",
        "    # Ch·ªâ ch·ªçn c√°c c·ªôt c√≥ √Ω nghƒ©a v·ªõi K-Means\n",
        "    cols = ['n_clusters', 'init', 'n_init',\n",
        "            'silhouette', 'calinski_harabasz', 'davies_bouldin']\n",
        "    # L·ªçc c√°c c·ªôt th·ª±c s·ª± t·ªìn t·∫°i trong df k·∫øt qu·∫£ (ƒë·ªÅ ph√≤ng l·ªói key)\n",
        "    cols = [c for c in cols if c in df_results.columns]\n",
        "    print(df_results[cols].head(5).to_string(index=False))\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid results found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "984ce6d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"DBSCAN HYPERPARAMETER TUNING - COMPOSITE METRIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Thi·∫øt l·∫≠p Grid cho DBSCAN\n",
        "# eps: Kho·∫£ng c√°ch t·ªëi ƒëa gi·ªØa 2 ƒëi·ªÉm ƒë·ªÉ ƒë∆∞·ª£c coi l√† c√πng v√πng l√¢n c·∫≠n\n",
        "# min_samples: S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ t·∫°o th√†nh 1 core point\n",
        "# metric: ƒê·ªô ƒëo kho·∫£ng c√°ch\n",
        "dbscan_grid = {\n",
        "    \"eps\": [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0],\n",
        "    \"min_samples\": [5, 10, 15, 20],\n",
        "    \"metric\": [\"euclidean\", \"manhattan\"]\n",
        "}\n",
        "\n",
        "print(\"Grid parameters:\")\n",
        "for key, values in dbscan_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "\n",
        "total = 1\n",
        "for v in dbscan_grid.values():\n",
        "    total *= len(v)\n",
        "print(f\"\\nTotal combinations: {total}\")\n",
        "\n",
        "# 2. Kh·ªüi t·∫°o Tuner v·ªõi COMPOSITE METRIC\n",
        "evaluator = ClusteringEvaluator()\n",
        "tuning_config = TuningConfig(\n",
        "    data_path=\"data/processed/encoded_data.csv\",\n",
        "    results_path=\"results/dbscan_composite_tuning.csv\",\n",
        "    metric_selection=\"composite\",  # S·ª≠ d·ª•ng composite score\n",
        "    silhouette_weight=0.4,\n",
        "    calinski_weight=0.3,\n",
        "    davies_weight=0.3\n",
        ")\n",
        "tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)\n",
        "\n",
        "print(f\"\\nüìä Using Composite Score:\")\n",
        "print(f\"   Silhouette weight     : {tuning_config.silhouette_weight}\")\n",
        "print(f\"   Calinski-Harabasz wt  : {tuning_config.calinski_weight}\")\n",
        "print(f\"   Davies-Bouldin wt     : {tuning_config.davies_weight}\")\n",
        "\n",
        "# 3. Ch·∫°y Tuning\n",
        "print(\"\\nüîÑ Running DBSCAN grid search...\")\n",
        "print(\"‚ö†Ô∏è  Note: DBSCAN c√≥ th·ªÉ t·∫°o nhi·ªÅu noise points (cluster -1)\")\n",
        "tuner.run_grid_search(\"dbscan\", dbscan_grid)\n",
        "\n",
        "# 4. L∆∞u k·∫øt qu·∫£\n",
        "tuner.save_results()\n",
        "\n",
        "# 5. L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t\n",
        "df_results = tuner.get_summary()\n",
        "\n",
        "if len(df_results) > 0:\n",
        "    best = df_results.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üèÜ BEST DBSCAN CONFIG (by Composite Score)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"  eps                    : {best['eps']}\")\n",
        "    print(f\"  min_samples            : {int(best['min_samples'])}\")\n",
        "    print(f\"  metric                 : {best['metric']}\")\n",
        "    print(f\"\\n  üìà METRICS:\")\n",
        "    print(f\"  Silhouette Score       : {best['silhouette']:.4f}\")\n",
        "    print(f\"  Calinski-Harabasz      : {best['calinski_harabasz']:.2f}\")\n",
        "    print(f\"  Davies-Bouldin Index   : {best['davies_bouldin']:.4f}\")\n",
        "    print(f\"  Composite Score        : {best['composite_score']:.4f}\")\n",
        "    print(f\"  Number of Clusters     : {int(best['n_clusters'])}\")\n",
        "\n",
        "    # Train v√† l∆∞u model t·ªët nh·∫•t\n",
        "    print(\"\\nüîÑ Training best model...\")\n",
        "    best_params = {\n",
        "        \"eps\": float(best['eps']),\n",
        "        \"min_samples\": int(best['min_samples']),\n",
        "        \"metric\": best['metric']\n",
        "    }\n",
        "\n",
        "    config = TrainingConfig(\n",
        "        data_path=\"data/processed/encoded_data.csv\",\n",
        "        model_type=\"dbscan\",\n",
        "        model_params=best_params,\n",
        "        model_path=\"results/dbscan_composite_best.pkl\"\n",
        "    )\n",
        "\n",
        "    trainer = ModelTrainer(config=config, evaluator=evaluator)\n",
        "    trainer.load_data()\n",
        "    trainer.train_model()\n",
        "    \n",
        "    # Ki·ªÉm tra s·ªë clusters v√† noise\n",
        "    labels = trainer.get_cluster_labels()\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise = list(labels).count(-1)\n",
        "    noise_pct = n_noise / len(labels) * 100\n",
        "    \n",
        "    print(f\"\\nüìä Cluster Analysis:\")\n",
        "    print(f\"  Total clusters (excluding noise): {n_clusters}\")\n",
        "    print(f\"  Noise points: {n_noise} ({noise_pct:.1f}%)\")\n",
        "    \n",
        "    trainer.save_model()\n",
        "    trainer.save_labels(\"results/dbscan_composite_best_labels.csv\")\n",
        "\n",
        "    print(\"\\n‚úÖ Best DBSCAN model saved!\")\n",
        "    print(\"   Model: results/dbscan_composite_best.pkl\")\n",
        "    print(\"   Labels: results/dbscan_composite_best_labels.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef2351c",
      "metadata": {},
      "source": [
        "## 5D. DBSCAN Tuning\n",
        "\n",
        "T√¨m best configuration cho DBSCAN (Density-Based Spatial Clustering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588fed64",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"GMM (Gaussian Mixture Model) - COMPOSITE METRIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Thi·∫øt l·∫≠p Grid cho GMM\n",
        "# n_clusters: S·ªë l∆∞·ª£ng Gaussian components\n",
        "# covariance_type: Lo·∫°i ma tr·∫≠n covariance\n",
        "#   - 'full': M·ªói component c√≥ ma tr·∫≠n covariance ri√™ng (linh ho·∫°t nh·∫•t)\n",
        "#   - 'tied': T·∫•t c·∫£ components d√πng chung 1 ma tr·∫≠n covariance\n",
        "#   - 'diag': Ma tr·∫≠n ƒë∆∞·ªùng ch√©o (assume features ƒë·ªôc l·∫≠p)\n",
        "#   - 'spherical': Ma tr·∫≠n ƒë∆∞·ªùng ch√©o v·ªõi variance b·∫±ng nhau\n",
        "# n_init: S·ªë l·∫ßn kh·ªüi t·∫°o ng·∫´u nhi√™n\n",
        "# max_iter: S·ªë v√≤ng l·∫∑p t·ªëi ƒëa cho EM algorithm\n",
        "gmm_grid = {\n",
        "    \"n_clusters\": [3, 4, 5, 6, 7, 8],\n",
        "    \"covariance_type\": [\"full\", \"tied\", \"diag\", \"spherical\"],\n",
        "    \"n_init\": [10],\n",
        "    \"max_iter\": [200]\n",
        "}\n",
        "\n",
        "print(\"Grid parameters:\")\n",
        "for key, values in gmm_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "\n",
        "total = 1\n",
        "for v in gmm_grid.values():\n",
        "    total *= len(v)\n",
        "print(f\"\\nTotal combinations: {total}\")\n",
        "\n",
        "# 2. Kh·ªüi t·∫°o Tuner v·ªõi COMPOSITE METRIC\n",
        "evaluator = ClusteringEvaluator()\n",
        "tuning_config = TuningConfig(\n",
        "    data_path=\"data/processed/encoded_data.csv\",\n",
        "    results_path=\"results/gmm_composite_tuning.csv\",\n",
        "    metric_selection=\"composite\",\n",
        "    silhouette_weight=0.4,\n",
        "    calinski_weight=0.3,\n",
        "    davies_weight=0.3\n",
        ")\n",
        "tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)\n",
        "\n",
        "print(f\"\\nüìä Using Composite Score:\")\n",
        "print(f\"   Silhouette weight     : {tuning_config.silhouette_weight}\")\n",
        "print(f\"   Calinski-Harabasz wt  : {tuning_config.calinski_weight}\")\n",
        "print(f\"   Davies-Bouldin wt     : {tuning_config.davies_weight}\")\n",
        "\n",
        "# 3. Ch·∫°y Tuning\n",
        "print(\"\\nüîÑ Running GMM grid search...\")\n",
        "print(\"üí° GMM l√† probabilistic model, m·ªói ƒëi·ªÉm c√≥ x√°c su·∫•t thu·ªôc t·ª´ng cluster\")\n",
        "tuner.run_grid_search(\"gmm\", gmm_grid)\n",
        "\n",
        "# 4. L∆∞u k·∫øt qu·∫£\n",
        "tuner.save_results()\n",
        "\n",
        "# 5. L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t\n",
        "df_results = tuner.get_summary()\n",
        "\n",
        "if len(df_results) > 0:\n",
        "    best = df_results.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üèÜ BEST GMM CONFIG (by Composite Score)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"  n_clusters             : {int(best['n_clusters'])}\")\n",
        "    print(f\"  covariance_type        : {best['covariance_type']}\")\n",
        "    print(f\"  n_init                 : {int(best['n_init'])}\")\n",
        "    print(f\"  max_iter               : {int(best['max_iter'])}\")\n",
        "    print(f\"\\n  üìà METRICS:\")\n",
        "    print(f\"  Silhouette Score       : {best['silhouette']:.4f}\")\n",
        "    print(f\"  Calinski-Harabasz      : {best['calinski_harabasz']:.2f}\")\n",
        "    print(f\"  Davies-Bouldin Index   : {best['davies_bouldin']:.4f}\")\n",
        "    print(f\"  Composite Score        : {best['composite_score']:.4f}\")\n",
        "\n",
        "    # Train v√† l∆∞u model t·ªët nh·∫•t\n",
        "    print(\"\\nüîÑ Training best model...\")\n",
        "    best_params = {\n",
        "        \"covariance_type\": best['covariance_type'],\n",
        "        \"n_init\": int(best['n_init']),\n",
        "        \"max_iter\": int(best['max_iter'])\n",
        "    }\n",
        "\n",
        "    config = TrainingConfig(\n",
        "        data_path=\"data/processed/encoded_data.csv\",\n",
        "        model_type=\"gmm\",\n",
        "        n_clusters=int(best['n_clusters']),\n",
        "        model_params=best_params,\n",
        "        model_path=\"results/gmm_composite_best.pkl\"\n",
        "    )\n",
        "\n",
        "    trainer = ModelTrainer(config=config, evaluator=evaluator)\n",
        "    trainer.load_data()\n",
        "    trainer.train_model()\n",
        "    trainer.save_model()\n",
        "    trainer.save_labels(\"results/gmm_composite_best_labels.csv\")\n",
        "\n",
        "    print(\"\\n‚úÖ Best GMM model saved!\")\n",
        "    print(\"   Model: results/gmm_composite_best.pkl\")\n",
        "    print(\"   Labels: results/gmm_composite_best_labels.csv\")\n",
        "\n",
        "    # Show top 5 configs\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä TOP 5 CONFIGS (by Composite Score)\")\n",
        "    print(\"=\"*80)\n",
        "    cols = ['n_clusters', 'covariance_type', 'n_init',\n",
        "            'silhouette', 'calinski_harabasz', 'davies_bouldin', 'composite_score']\n",
        "    cols = [c for c in cols if c in df_results.columns]\n",
        "    print(df_results[cols].head(5).to_string(index=False))\n",
        "    \n",
        "    # Ph√¢n t√≠ch covariance type performance\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä COVARIANCE TYPE COMPARISON\")\n",
        "    print(\"=\"*80)\n",
        "    if 'covariance_type' in df_results.columns:\n",
        "        cov_analysis = df_results.groupby('covariance_type').agg({\n",
        "            'silhouette': 'mean',\n",
        "            'calinski_harabasz': 'mean',\n",
        "            'davies_bouldin': 'mean',\n",
        "            'composite_score': 'mean'\n",
        "        }).round(4)\n",
        "        print(cov_analysis)\n",
        "        print(\"\\nüí° Interpretation:\")\n",
        "        print(\"   - 'full': T·ªët nh·∫•t nh∆∞ng t·ªën b·ªô nh·ªõ (n_features¬≤)\")\n",
        "        print(\"   - 'tied': C√¢n b·∫±ng gi·ªØa flexibility v√† efficiency\")\n",
        "        print(\"   - 'diag': Nhanh, ph√π h·ª£p v·ªõi high-dimensional data\")\n",
        "        print(\"   - 'spherical': Nhanh nh·∫•t nh∆∞ng √≠t linh ho·∫°t\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid results found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2a31763",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"HDBSCAN - COMPOSITE METRIC\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Thi·∫øt l·∫≠p Grid cho HDBSCAN\n",
        "# min_cluster_size: S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu trong 1 cluster (quan tr·ªçng nh·∫•t!)\n",
        "# min_samples: S·ªë ƒëi·ªÉm trong neighborhood ƒë·ªÉ t√≠nh core distance\n",
        "# metric: ƒê·ªô ƒëo kho·∫£ng c√°ch\n",
        "# cluster_selection_method:\n",
        "#   - 'eom' (Excess of Mass): Ch·ªçn cluster stable nh·∫•t\n",
        "#   - 'leaf': Ch·ªçn leaf clusters trong hierarchy tree\n",
        "hdbscan_grid = {\n",
        "    \"min_cluster_size\": [10, 20, 30, 50, 100],\n",
        "    \"min_samples\": [10, 20],\n",
        "    \"metric\": [\"euclidean\", \"manhattan\"],\n",
        "    \"cluster_selection_method\": [\"eom\"]\n",
        "}\n",
        "\n",
        "print(\"Grid parameters:\")\n",
        "for key, values in hdbscan_grid.items():\n",
        "    print(f\"  {key}: {values}\")\n",
        "\n",
        "total = 1\n",
        "for v in hdbscan_grid.values():\n",
        "    total *= len(v)\n",
        "print(f\"\\nTotal combinations: {total}\")\n",
        "\n",
        "# 2. Kh·ªüi t·∫°o Tuner v·ªõi COMPOSITE METRIC\n",
        "evaluator = ClusteringEvaluator()\n",
        "tuning_config = TuningConfig(\n",
        "    data_path=\"data/processed/encoded_data.csv\",\n",
        "    results_path=\"results/hdbscan_composite_tuning.csv\",\n",
        "    metric_selection=\"composite\",\n",
        "    silhouette_weight=0.4,\n",
        "    calinski_weight=0.3,\n",
        "    davies_weight=0.3\n",
        ")\n",
        "tuner = HyperparameterTuner(config=tuning_config, evaluator=evaluator)\n",
        "\n",
        "print(f\"\\nüìä Using Composite Score:\")\n",
        "print(f\"   Silhouette weight     : {tuning_config.silhouette_weight}\")\n",
        "print(f\"   Calinski-Harabasz wt  : {tuning_config.calinski_weight}\")\n",
        "print(f\"   Davies-Bouldin wt     : {tuning_config.davies_weight}\")\n",
        "\n",
        "# 3. Ch·∫°y Tuning\n",
        "print(\"\\nüîÑ Running HDBSCAN grid search...\")\n",
        "print(\"üí° HDBSCAN advantages:\")\n",
        "print(\"   ‚úÖ T·ª± ƒë·ªông t√¨m s·ªë clusters (kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh K)\")\n",
        "print(\"   ‚úÖ Ph√°t hi·ªán clusters v·ªõi m·∫≠t ƒë·ªô kh√°c nhau\")\n",
        "print(\"   ‚úÖ Robust v·ªõi noise v√† outliers\")\n",
        "tuner.run_grid_search(\"hdbscan\", hdbscan_grid)\n",
        "\n",
        "# 4. L∆∞u k·∫øt qu·∫£\n",
        "tuner.save_results()\n",
        "\n",
        "# 5. L·∫•y k·∫øt qu·∫£ t·ªët nh·∫•t\n",
        "df_results = tuner.get_summary()\n",
        "\n",
        "if len(df_results) > 0:\n",
        "    best = df_results.iloc[0]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üèÜ BEST HDBSCAN CONFIG (by Composite Score)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"  min_cluster_size          : {int(best['min_cluster_size'])}\")\n",
        "    print(f\"  min_samples               : {int(best['min_samples'])}\")\n",
        "    print(f\"  metric                    : {best['metric']}\")\n",
        "    print(f\"  cluster_selection_method  : {best['cluster_selection_method']}\")\n",
        "    print(f\"\\n  üìà METRICS:\")\n",
        "    print(f\"  Silhouette Score          : {best['silhouette']:.4f}\")\n",
        "    print(f\"  Calinski-Harabasz         : {best['calinski_harabasz']:.2f}\")\n",
        "    print(f\"  Davies-Bouldin Index      : {best['davies_bouldin']:.4f}\")\n",
        "    print(f\"  Composite Score           : {best['composite_score']:.4f}\")\n",
        "    print(f\"  Number of Clusters        : {int(best['n_clusters'])}\")\n",
        "\n",
        "    # Train v√† l∆∞u model t·ªët nh·∫•t\n",
        "    print(\"\\nüîÑ Training best model...\")\n",
        "    best_params = {\n",
        "        \"min_cluster_size\": int(best['min_cluster_size']),\n",
        "        \"min_samples\": int(best['min_samples']),\n",
        "        \"metric\": best['metric'],\n",
        "        \"cluster_selection_method\": best['cluster_selection_method']\n",
        "    }\n",
        "\n",
        "    config = TrainingConfig(\n",
        "        data_path=\"data/processed/encoded_data.csv\",\n",
        "        model_type=\"hdbscan\",\n",
        "        model_params=best_params,\n",
        "        model_path=\"results/hdbscan_composite_best.pkl\"\n",
        "    )\n",
        "\n",
        "    trainer = ModelTrainer(config=config, evaluator=evaluator)\n",
        "    trainer.load_data()\n",
        "    trainer.train_model()\n",
        "    \n",
        "    # Ki·ªÉm tra s·ªë clusters v√† noise\n",
        "    labels = trainer.get_cluster_labels()\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise = list(labels).count(-1)\n",
        "    noise_pct = n_noise / len(labels) * 100\n",
        "    \n",
        "    print(f\"\\nüìä Cluster Analysis:\")\n",
        "    print(f\"  Total clusters (excluding noise): {n_clusters}\")\n",
        "    print(f\"  Noise points: {n_noise} ({noise_pct:.1f}%)\")\n",
        "    \n",
        "    # Ph√¢n b·ªë k√≠ch th∆∞·ªõc clusters\n",
        "    if n_clusters > 0:\n",
        "        cluster_sizes = pd.Series(labels).value_counts().sort_index()\n",
        "        cluster_sizes = cluster_sizes[cluster_sizes.index != -1]  # Lo·∫°i noise\n",
        "        print(f\"\\n  Cluster size distribution:\")\n",
        "        for cluster_id, size in cluster_sizes.items():\n",
        "            pct = size / len(labels) * 100\n",
        "            print(f\"    Cluster {cluster_id}: {size} samples ({pct:.1f}%)\")\n",
        "    \n",
        "    trainer.save_model()\n",
        "    trainer.save_labels(\"results/hdbscan_composite_best_labels.csv\")\n",
        "\n",
        "    print(\"\\n‚úÖ Best HDBSCAN model saved!\")\n",
        "    print(\"   Model: results/hdbscan_composite_best.pkl\")\n",
        "    print(\"   Labels: results/hdbscan_composite_best_labels.csv\")\n",
        "\n",
        "    # Show top 5 configs\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä TOP 5 CONFIGS (by Composite Score)\")\n",
        "    print(\"=\"*80)\n",
        "    cols = ['min_cluster_size', 'min_samples', 'metric', 'n_clusters',\n",
        "            'silhouette', 'calinski_harabasz', 'davies_bouldin', 'composite_score']\n",
        "    cols = [c for c in cols if c in df_results.columns]\n",
        "    print(df_results[cols].head(5).to_string(index=False))\n",
        "    \n",
        "    # Ph√¢n t√≠ch min_cluster_size impact\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä MIN_CLUSTER_SIZE IMPACT ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "    if 'min_cluster_size' in df_results.columns:\n",
        "        size_analysis = df_results.groupby('min_cluster_size').agg({\n",
        "            'n_clusters': 'mean',\n",
        "            'silhouette': 'mean',\n",
        "            'calinski_harabasz': 'mean',\n",
        "            'composite_score': 'mean'\n",
        "        }).round(2)\n",
        "        print(size_analysis)\n",
        "        print(\"\\nüí° Interpretation:\")\n",
        "        print(\"   - min_cluster_size nh·ªè ‚Üí nhi·ªÅu clusters, c√≥ th·ªÉ over-segment\")\n",
        "        print(\"   - min_cluster_size l·ªõn ‚Üí √≠t clusters, c√≥ th·ªÉ under-segment\")\n",
        "        print(\"   - Ch·ªçn value c√¢n b·∫±ng gi·ªØa s·ªë clusters v√† quality metrics\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No valid results found\")\n",
        "    print(\"üí° Tip: HDBSCAN c√≥ th·ªÉ kh√¥ng t√¨m ƒë∆∞·ª£c c·∫•u h√¨nh t·ªët n·∫øu:\")\n",
        "    print(\"   - min_cluster_size qu√° l·ªõn so v·ªõi dataset size\")\n",
        "    print(\"   - Data kh√¥ng c√≥ c·∫•u tr√∫c hierarchical density r√µ r√†ng\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcd0e10",
      "metadata": {},
      "source": [
        "## 5F. HDBSCAN Tuning\n",
        "\n",
        "T√¨m best configuration cho HDBSCAN (Hierarchical Density-Based Spatial Clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2d2e6f",
      "metadata": {},
      "source": [
        "## 5E. GMM Tuning\n",
        "\n",
        "T√¨m best configuration cho Gaussian Mixture Model (GMM)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
